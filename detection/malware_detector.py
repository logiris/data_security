import re
from typing import Dict, List, Optional, Union
import numpy as np
from pathlib import Path
import logging
from transformers import BertTokenizer, BertForSequenceClassification
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import joblib

class MalwareDetector:
    """恶意代码检测器类"""
    
    def __init__(self, 
                 use_bert: bool = True,
                 model_path: Optional[Union[str, Path]] = None):
        """初始化检测器
        
        Args:
            use_bert: 是否使用BERT模型
            model_path: 预训练模型路径
        """
        self.use_bert = use_bert
        self.model_path = model_path
        
        # 配置日志
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # 初始化模型
        if use_bert:
            self._init_bert_model()
        else:
            self._init_tfidf_model()
    
    def _init_bert_model(self):
        """初始化BERT模型"""
        try:
            if self.model_path:
                self.tokenizer = BertTokenizer.from_pretrained(str(self.model_path))
                self.model = BertForSequenceClassification.from_pretrained(str(self.model_path))
            else:
                self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')
                self.model = BertForSequenceClassification.from_pretrained('bert-base-chinese')
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            self.model.to(self.device)
            self.model.eval()
        except Exception as e:
            self.logger.error(f"Error initializing BERT model: {e}")
            self.use_bert = False
            self._init_tfidf_model()
    
    def _init_tfidf_model(self):
        """初始化TF-IDF模型"""
        self.vectorizer = TfidfVectorizer(
            max_features=10000,
            ngram_range=(1, 3),
            stop_words='english'
        )
        self.classifier = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
    
    def detect_sql_injection(self, text: str) -> Dict[str, Union[bool, List[str]]]:
        """检测SQL注入攻击
        
        Args:
            text: 待检测文本
            
        Returns:
            检测结果字典
        """
        patterns = {
            'union_select': r'(?i)UNION\s+SELECT',
            'sleep': r'(?i)SLEEP\s*\(',
            'benchmark': r'(?i)BENCHMARK\s*\(',
            'information_schema': r'(?i)INFORMATION_SCHEMA',
            'comment': r'(?i)--\s*$|/\*.*?\*/',
            'concat': r'(?i)CONCAT\s*\(',
            'group_concat': r'(?i)GROUP_CONCAT\s*\(',
        }
        
        matches = {}
        for name, pattern in patterns.items():
            matches[name] = re.findall(pattern, text)
        
        is_malicious = any(matches.values())
        return {
            'is_malicious': is_malicious,
            'matches': matches
        }
    
    def detect_xss(self, text: str) -> Dict[str, Union[bool, List[str]]]:
        """检测XSS攻击
        
        Args:
            text: 待检测文本
            
        Returns:
            检测结果字典
        """
        patterns = {
            'script_tag': r'<script[^>]*>.*?</script>',
            'javascript': r'javascript:',
            'on_event': r'on\w+\s*=',
            'eval': r'eval\s*\(',
            'document_cookie': r'document\.cookie',
        }
        
        matches = {}
        for name, pattern in patterns.items():
            matches[name] = re.findall(pattern, text)
        
        is_malicious = any(matches.values())
        return {
            'is_malicious': is_malicious,
            'matches': matches
        }
    
    def detect_command_injection(self, text: str) -> Dict[str, Union[bool, List[str]]]:
        """检测命令注入攻击
        
        Args:
            text: 待检测文本
            
        Returns:
            检测结果字典
        """
        patterns = {
            'system': r'(?i)system\s*\(',
            'exec': r'(?i)exec\s*\(',
            'shell_exec': r'(?i)shell_exec\s*\(',
            'backtick': r'`.*?`',
            'pipe': r'\|.*?$',
        }
        
        matches = {}
        for name, pattern in patterns.items():
            matches[name] = re.findall(pattern, text)
        
        is_malicious = any(matches.values())
        return {
            'is_malicious': is_malicious,
            'matches': matches
        }
    
    def detect_malware_bert(self, text: str) -> Dict[str, float]:
        """使用BERT模型检测恶意代码
        
        Args:
            text: 待检测文本
            
        Returns:
            检测结果字典，包含各类别的概率
        """
        if not self.use_bert:
            return {'error': 'BERT model not initialized'}
        
        try:
            inputs = self.tokenizer(
                text,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors='pt'
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.softmax(outputs.logits, dim=1)
            
            return {
                'malicious': float(probabilities[0][1]),
                'benign': float(probabilities[0][0])
            }
        except Exception as e:
            self.logger.error(f"Error in BERT detection: {e}")
            return {'error': str(e)}
    
    def detect_malware_tfidf(self, text: str) -> Dict[str, float]:
        """使用TF-IDF模型检测恶意代码
        
        Args:
            text: 待检测文本
            
        Returns:
            检测结果字典，包含各类别的概率
        """
        try:
            features = self.vectorizer.transform([text])
            probabilities = self.classifier.predict_proba(features)[0]
            
            return {
                'malicious': float(probabilities[1]),
                'benign': float(probabilities[0])
            }
        except Exception as e:
            self.logger.error(f"Error in TF-IDF detection: {e}")
            return {'error': str(e)}
    
    def train_tfidf_model(self, 
                         texts: List[str],
                         labels: List[int],
                         save_path: Optional[Union[str, Path]] = None):
        """训练TF-IDF模型
        
        Args:
            texts: 训练文本列表
            labels: 训练标签列表
            save_path: 模型保存路径
        """
        try:
            # 特征提取
            features = self.vectorizer.fit_transform(texts)
            
            # 训练分类器
            self.classifier.fit(features, labels)
            
            # 保存模型
            if save_path:
                save_path = Path(save_path)
                save_path.mkdir(parents=True, exist_ok=True)
                
                joblib.dump(self.vectorizer, save_path / 'vectorizer.joblib')
                joblib.dump(self.classifier, save_path / 'classifier.joblib')
                
                self.logger.info(f"Model saved to {save_path}")
        except Exception as e:
            self.logger.error(f"Error training TF-IDF model: {e}")
    
    def load_tfidf_model(self, model_path: Union[str, Path]):
        """加载TF-IDF模型
        
        Args:
            model_path: 模型路径
        """
        try:
            model_path = Path(model_path)
            self.vectorizer = joblib.load(model_path / 'vectorizer.joblib')
            self.classifier = joblib.load(model_path / 'classifier.joblib')
            self.logger.info(f"Model loaded from {model_path}")
        except Exception as e:
            self.logger.error(f"Error loading TF-IDF model: {e}")
    
    def detect(self, text: str) -> Dict[str, Union[bool, float, List[str]]]:
        """综合检测恶意代码
        
        Args:
            text: 待检测文本
            
        Returns:
            综合检测结果字典
        """
        results = {
            'sql_injection': self.detect_sql_injection(text),
            'xss': self.detect_xss(text),
            'command_injection': self.detect_command_injection(text)
        }
        
        # 使用机器学习模型检测
        if self.use_bert:
            ml_results = self.detect_malware_bert(text)
        else:
            ml_results = self.detect_malware_tfidf(text)
        
        results['ml_detection'] = ml_results
        
        # 综合判断
        is_malicious = (
            results['sql_injection']['is_malicious'] or
            results['xss']['is_malicious'] or
            results['command_injection']['is_malicious'] or
            (isinstance(ml_results, dict) and 
             'malicious' in ml_results and 
             ml_results['malicious'] > 0.5)
        )
        
        results['is_malicious'] = is_malicious
        return results 